#import "@preview/physica:0.9.2": *
#import "systemB.typ": *

#show: graduation_thesis.with(
  title: "独立深層学習行列分析に基づく\n拡散性雑音下教師有り\nリアルタイム多チャネル音声抽出",
  your_name_jp: "仲西優貴",
  your_name_en: "Yuki Nakanishi",
  student_id: "03-230625",
  mentor_name: "猿渡洋",
  mentor_position: "教授",
  write_year: "2025",
  write_month: "1",
  abstract: "　本論文では，deep neural network (DNN) に基づく音源モデルを導入した拡散性雑音下でのリアルタイム音声抽出フレームワークを提案する．音声抽出とは，目的音声と雑音が混合した観測信号から目的音声を抽出する技術である．拡散性雑音はあらゆる環境に存在するため，拡散性雑音下での音声抽出技術は音声認識システムや補聴器システムに応用することが可能である．このような応用を行う場合には，音声抽出はリアルタイムに行われる必要がある．\n　本論文は拡散性雑音下におけるリアルタイム音声抽出においてDNNで音源モデルを推定するフレームワークを提案する．本フレームワークはランク制約付き空間共分散行列推定法 (RCSCME) のリアルタイム動作を行う．RCSCMEは独立低ランク行列分析 (ILRMA) と呼ばれる手法とランク制約のある空間共分散行列の推定手法を組み合わせた，拡散性雑音下での高い音声抽出性能を持つ手法である．しかしILRMAには連続的なスペクトルを持つ音声に対する音源の分離性能が限定的であるという問題がある．そこで，音声抽出で用いるILRMAは分離行列を求めることができれば他の手法で代替可能であることを考慮し，音声抽出の前段として独立深層学習行列分析 (IDLMA) を導入し，DNNによる音源モデルの推定を行い音源を分離するリアルタイム音声抽出を提案する．また，単チャネルDNNにより抽出された音声から音声の雑音のみの区間を推定し，得られた雑音の空間共分散行列をRCSCMEの事前分布としてリアルタイム音声抽出に用いることを提案する．提案手法が従来のILRMAを前段としたリアルタイム音声抽出よりも音声抽出性能において優れることを実験的に示す．",
  bibliography-file: "./references.bib",
)

= 序論

== 本論文の背景
音声抽出とは，目的となる音声と雑音が混合した観測信号から目的となる音声を抽出する技術である．マイクロホンなどで音を捉える際には目的音声と雑音の混合音を捉えているため，目的音声を何らかの形で利用するためには混合音から目的音声を抽出する必要がある．音声抽出技術を活用することで，例えば会話などにおいて背景雑音を抑制したクリアな声をユーザに提示することができる@Musti2013 @Une2019 ．音声認識システムの入力音声に対して音声抽出技術を適用して雑音を抑制することで，より精度の高い音声認識を期待することができる@Takahashi2010．\
caption: [Application of speech extraction])<fig1>
　次に音源分離および音声抽出手法について述べる．音源分離とは，複数の音源から到来した音が混合した観測信号からそれぞれの混合前の信号を分離する技術である．したがって目的とする音声を抽出するための音声抽出に音源分離技術を応用することができる．音源分離問題は，観測に用いるマイクロホン数が単数 (単チャネル) か複数 (多チャネル) か，および学習を事前情報無しで行う (ブラインド) か事前情報ありで行うかの観点で分類することができる．単チャネルの場合音響的特徴のみしか用いることができない一方で，多チャネルの場合は空間的特徴を利用して音源分離を行うことが可能である．\
　ブラインドでない分離手法としては，Wiener フィルタ@Wiener1964 やビームフォーマ@Capon1969 @Frost1982 @Grif1982 がある．Wiener フィルタは最小平均二乗誤差規範により，目的音源および雑音源のパワースペクトログラムを用いて目的音源のパワースペクトログラムを推定する．ビームフォーマでは，マイクロホンアレイの位置関係や目的音源の到来方向の情報を用いて目的音源を推定する．ただしこれらの手法は目的音源や雑音源の音響的情報や空間的情報を必要とし，十分でなければ推定精度が低下する恐れがある．\
　音源信号や収音環境について全て未知であるとする手法はブラインド音源分離 (blind source separation: BSS) と呼ばれる@Sawada2019．BSSには事前情報が必要ないため，様々な状況で利用することが可能である．単チャネルのBSSの手法としては，音源のパワースペクトログラムの持つ特徴をモデル化することで分離を行う非負値行列因子分解 (nonnegative matrix factorization: NMF) @Lee1999 が提案されている @Smara2007 ．一方で多チャネルの場合には空間的な情報を用いてより高精度に分離をすることができる．多チャネルのBSSの手法には，時間領域における瞬時混合を仮定した独立成分分析 (independent component analysis: ICA) @Comon1994 @Bell1995 @Amari1995 がある．しかしこの手法は畳み込み混合された信号に直接適用することができない．そこで短時間 Fourier 変換 (short-time Fourier transform: STFT) で時間周波数領域に変換したときに残響長がSTFTの窓長よりも十分短ければ周波数ごとの瞬時混合とみなせることを用いて，畳み込み混合信号にICAを適用する手法である周波数領域独立成分分析 (frequency-domain ICA: FDICA) @Smara1998 @Ikeda1999 @Saru2006 が提案されている．FDICAは各周波数ビンごとの統計的独立性のみに基づくため，各出力信号の大きさが定まらない問題 (スケール問題) や周波数ビンの順番が定まらない問題 (パーミュテーション問題) が生じる．スケール問題については，複数のマイクロホンから基準となるマイクロホンを選択し，各分離信号の総和がそのマイクロホンの観測信号に一致するようスケールを定める projection back (PB) 法 @Murata2001 が提案されている．パーミュテーションを解決して音源分離を行うための手法として，FDICAを改良した独立ベクトル分析 (IVA) @Hiroe2006 @Kim2007 @Ono2011 が提案されている．さらにIVAの音源のパワースペクトログラムをNMFで表現する独立低ランク行列分析 (independent low-rank matrix analysis: ILRMA) @Kitamura2016 @Kitamura2018 により，さらに高精度の音源分離が達成されている．これらの手法は分離音の歪みを抑制して分離することが可能であるが，背景雑音として全方位から到来する拡散性雑音を完全に除去することは不可能であり，分離された目的音に雑音成分が残留してしまう @Araki2003 ．複数音源の混合音から１つの独立な成分を抽出する独立ベクトル抽出 (independent vector extraction: IVE) @Kold2019 が提案されているが，モデル自体はFDICAと同様に点音源仮定に基づいているため，拡散性を有する雑音下での分離性能は限定的である．また，FDICAやIVA，ILRMAなどの線形時不変なフィルタでの分離を前段処理として実行し，その出力に対しWienerフィルタやスペクトル減算 @Boll1979 等の単チャネル手法を適用して雑音を抑制する手法が数多く提案されている @Kim1996 @Mizumachi1998 @Saru2000 @Meyer1997 @McCowan2003 @Kolossa2004 @Sawada2006 @Mori2006 @Takahashi2009 @Miyazaki2011 が，これらの手法は厳密には統計的枠組みに基づいておらず精度は限定的である @Saru2010．\
　その他の多チャネルBSS手法としては，各音源の空間特徴を表す空間共分散行列 (spatial covariance matrix: SCM) を用いるフルランクSCMモデルが提案されている @Duong2010．フルランクSCMモデルは線形時不変な分離フィルタを用いる分離手法の空間モデルと比較して自由度が高く，拡散性の音源を適切にモデル化できると考えられる．また，各音源のパワースペクトログラムをNMFによりモデル化した多チャネルNMF (multichannel NMF: MNMF) @Ozerov2010 @Sawada2013 や，モデル近似によりMNMFのパラメータ数を減らして計算コストを削減したFastNMF @Ito2019 @Sekiguchi2019 が提案されているが，計算コストが高いことや初期値に頑健でないこと，分離音が歪んでしまうことなどの問題点がある@Kitamura2016 ．\
　拡散性雑音下での音声抽出において，拡散性雑音をモデル化し高い音声抽出性能を持つブラインド音声抽出手法として，ランク制約付き空間共分散行列推定法 (rank-constrained SCM estimation: RCSCME) @Kubo2020 が提案されている．この手法の前段処理としてILRMAなどの音源間の独立性に基づく線形時不変分離フィルタによる音源分離を行う．拡散性雑音下で $M$ 個のマイクロホンを用いてこの前段処理を実行すると，拡散性雑音のみからなる $M-1$ 個の分離音と，目的音声と拡散性雑音からなる $1$ 個の分離音が得られる @Takahashi2009 ．目的音声の含まれない $M-1$ 個の分離音から，雑音SCMのランク $M-1$ 成分を推定できる．また，点音源である目的音声を正確に打ち消す $M-1$ 個の雑音の分離フィルタから，目的音声のステアリングベクトルを高精度に推定することができる．さらにSCMの残りランク $1$ 成分と目的音声や雑音に関する残りのパラメータを推定し，これらを多チャネルWienerフィルタに適用する．RCSCMEはMNMFやFastNMFよりも計算コストが低く，初期値に頑健であり，高い音声抽出性能を実現している．さらにRCSCMEは高速に動作させることが可能であるため，前段処理としてILRMAを用いて後段でRCSCMEを実行するリアルタイム音声抽出システム @Ishikawa2024 が提案され，リアルタイムに高い精度の音声抽出が実現することが確認されている．\
　BSSは事前情報を一切未知とする一方で，近年は膨大な音のデータベースを活用して音源分離を行う教師あり音源分離の枠組みが注目されている．音のデータベースとは観測信号に含まれる音源と同じ種類の異なる音源を集めたものである．例えば，ピアノのデータベースには様々な楽曲を演奏したピアノの音が収録される．このような蓄積されたデータベースを利用して音源信号の周波数構造のような特徴を学習することできる．この枠組みにおいてdeep neural network (DNN) は単チャネル分離 @Grais2014 @Uhlich2015 @Jansson2017 @Hershey2016 と多チャネル分離 @Nugraha2016 @Araki2015 @Tu2017 @Qian2018 の両方で高い性能を達成している．DNNでは十分な録音データ数が確保されている場合，その時間周波数構造を効果的にモデル化することができる．一方で空間モデルについては．部屋の形状や観測マイクロホンの位置，音源位置の微小な変化に多大な影響を受けるため，DNNにより汎用的な空間モデルを学習することは困難である．したがって，学習済みDNNモデルによる音源モデル推論とブラインドな空間モデル推定を組み合わせるのは合理的である．フルランクSCMの枠組みにDNNによる音源モデルを導入した多チャネル音源分離の枠組み @Grais2014 が提案されているが，空間共分散の推定に大きな計算コストがかかる上に空間パラメータの推定は困難であり精度が十分でない@Kitamura2016 ．より空間モデルのパラメータが少なく軽量で安定した手法として，独立深層学習行列分析 (independent deeply learned matrix analysis: IDLMA) @Makishima2019 が提案されている．IDLMAはICAによる分離行列のブラインド推定とDNNによる音源モデルの教師あり推論を組み合わせた分離手法であり，ILRMAのNMF音源モデルよりも柔軟な音源モデルであるためNMFでモデル化が困難な非低ランクな音源信号も適切にモデル化することが期待される．IDLMAは元々音楽分離に提案された手法であるが，音声強調にIDLMAを利用すること @Misawa2021 も提案され，雑音環境での音声強調において優れた音声強調性能を示すことが確認されている．
== 本論文の目的


== 本論文の構成
第2章では，従来手法としてILRMA，RCSCME，リアルタイム音声抽出，および独立深層学習行列分析を用いた音声抽出について述べる．第3章では，拡散性雑音下での独立深層学習行列分析を用いたリアルタイム音声抽出のフレームワークを提案し，単チャネル音声抽出DNNの出力に基づく雑音の空間共分散行列の事前分布のRCSCMEへの導入について述べる．第4章では，音声抽出性能の実験的評価により提案手法の有効性を確認する．第5章では本論文の結論を述べる．
#pagebreak()

= 従来手法

== はじめに
　本章では，提案手法について説明する上で必要となる従来手法を説明する．2.2節では点音源から到来する音に対するブラインド音源分離手法であるILRMAについて説明する．2.3節では拡散性雑音下での音声強調手法であるRCSCMEについて説明する．続いて2.4節では，ILRMAを用いたリアルタイム音声抽出フレームワークの先行研究について説明する．2.5節では，RCSCMEの前段として独立深層学習行列分析を用いた音声強調手法について説明する．最後に2.6節で本章のまとめを述べる．

== ILRMA
　本節では，音源は点音源であり残響時間がSTFTの窓長よりも十分に長いことを仮定する。

== RCSCME


== 拡散性雑音下でのリアルタイム音声抽出


== 独立深層学習行列分析に基づく音声抽出


== まとめ

#pagebreak()
= 独立深層学習行列分析に基づくリアルタイム音声抽出


== はじめに


== DNNを用いた音源モデル推定


== 目的音声欠損に対する補完処理


== 雑音自己教師あり空間共分散行列の推定


== 雑音自己教師あり空間共分散行列を事前分布とするリアルタイムRCSCME


== まとめ

#pagebreak()
= 実験的評価


== はじめに


== 実験条件


== 各パラメータを変化させた時の音声抽出性能の変化


== 各提案手法の音声抽出性能の比較


== まとめ


#pagebreak()
= 結論

#pagebreak()
// 見出しのないheading
#chap[謝辞]
